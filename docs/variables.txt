Compiling variables.

Ideally we would compile Python variables into Haskell variables. But Python
variables can be updated inside loops and closures, whereas Haskell variables
cannot. The next best thing is to use IORefs. A promising scheme is to
compile each Python variable into a Haskell variable bound to an IORef. A read
from a Python variable becomes a readIORef, likewise writeIORef.

A few problems still remain. Python's scoping rules are slightly different to
Haskell.

Nested references to variables can be annotated as "global" and "nonlocal", otherwise
a nested assignment creates a new local variable. The main issue is that Python
variable binding (declaration) sites are potentially ambiguous (there is no separate syntax
to introduce a new variable - assignment is used, but this is problematic when
another variable of the same name is already in scope).

Here is an example:

x = 12
def f():
   x = 144
   def g():
     global x
     x = 42
   g()
f()
print(x)

This prints 42. If you remove the "global x" then the program prints 12.
Note that the "global x" causes the innermost x to refer to the outermost x, thus
skipping the one in the middle. Haskell's nested scoping does not have an
equivalent way to skip enclosing scope.

One possible way to avoid this is to rename global variables, in psuedo
compiled haskell:

global_x = newVariable "x"
writeIORef global_x 12
f = def (\[] -> do
   x = newVariable "x"
   writeIORef x 144
   g = def (\[] -> do
     writeIORef global_x 42
     )
   g @@ []
   )
f @@ []
print @@ [global_x]

This looks good but has problems with "nonlocal".

In any case there remain some issues. The global scope of a module needs to be
treated specially (and differently) to local scopes. This is because the global
scope is not statically determined and this is visible in the variables
exported by the module (which become attributes of the module object returned
by the module when it is evaluated).

For example, we can have at the top level:

if cond:
   x = 12
else:
   y = 12

Depending on the result of evaluating 'cond', either x will be defined or y
will be defined, but (assuming this is all the code to consider) not both.
This will be visible in the attributes of the module object arising from this
code. A related aspect is caused by the star style of import:

from Foo import *

When compiling this statement we don't know what variables will be bound.
We will only discover these variables at runtime when the code is executed.

We note that CPython does not allow 'star' imports in non-global scopes,
presumably for the very problems/reasons mentioned in these notes.

The upshot of this is that we need to treat the global scope in a dynamic
fashion instead of a static fashion. As an aside, we didn't learn of this issue until
we tried to compile modules. It was hoped that all variables could be
treated uniformly as IORefs. It seems likely that we can treat local scopes
by using IORefs, but for the global scope we will have to use a dictionary
passed around in (the state part of) the Eval monad. This means when we compile
the program we need to distinguish between local and global variables.

It also
means that functions definitions will have to be "closed" over their global scope
at the point of definition, and carry that global scope with them. When a function
is called it will have to push its global scope onto some kind of stack and pop it
off when the function returns. It is useful to separate the global stack from the
control stack. We would not want to have to search the top of the control stack for
every global variable reference.

Incidentally
CPython includes a __globals__ attribute on functions for this very purpsoe.
CPython also has a __closure__ although it is not clear that we can (or want to)
support this. For locals we are using Haskell closures to implement Python closures
which is hopefully reasonably efficient. It would seem to be rather unfortunate
if we had to implement local scopes as dictionaries. Imagine an inner loop which
reads repeatedly from a variable. It would entail a lot of dictionary lookups.

I think that the different handling of the global scope will also sort out the
problem of "global" declarations mentioned above.

We will need two ways of working with variables: local and global. Eg:

   readLocal, writeLocal, readGlobal, writeGlobal.

Local variables need to be declared (because they are IORefs) but globals will
not. The first use of a global will cause it to be added to the state.

Also we need to make sure other variable binding things are treated correctly
depending on scope, eg def, class. Might need

   defLocal, defGlobal, classLocal, classGlobal

or can we get away with just def and klass, but use writeLocal, writeGlobal
to get the scope correct? The latter approach sounds best.

It would be cute if we could handle variable scope in the same pass as compiling the
code rather than having to make two passes. Unfortunately Python allows "global"
and "nonlocal" to come after the first use of a variable, like so:

   def f():
      x = 12
      global x

This means we can't compile the statement "x = 12" correctly until we've seen the following
global declaration. Python does issue a warning for this, but it still treats the x as
a global variable. So it seems like we have to pass over the body of the function to collect
all the 'global' and 'nonlocal' statements.

Another example of why we can't do one pass:

   def f():
      y = x + 1
      x = 12

Python gives this error, when f is called:

   UnboundLocalError: local variable 'x' referenced before assignment

From this we can infer that the fact that x is assigned in the local scope means that 
it is treated as local. Curiously it makes no difference if x is defined in an enclosing
scope. It is still treated as local.
